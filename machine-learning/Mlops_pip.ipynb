{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/dcxzz51RlH+9KPmUs7/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MELAI-1/MY-PROJECT/blob/main/machine-learning/Mlops_pip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation of MLOps Pipeline**"
      ],
      "metadata": {
        "id": "3I2yUAOJuQiI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing an MLOps pipeline means creating a system where machine learning models can be built, tested, deployed and monitored smoothly. Below is a step-by-step guide to build this pipeline using Python, Docker and Kubernetes."
      ],
      "metadata": {
        "id": "TSHG4P2VuWtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1: Data Ingestion and Preprocessing**"
      ],
      "metadata": {
        "id": "uiM8nkrguc0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Airflow is a tool for orchestrating data pipelines. Here's an example DAG (Directed Acyclic Graph) that automates data ingestion and preprocessing:"
      ],
      "metadata": {
        "id": "cx8TNRESukvK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV34slJPuFaZ"
      },
      "outputs": [],
      "source": [
        "from airflow import DAG\n",
        "from airflow.operators.python_operator import PythonOperator\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def preprocess_data():\n",
        "    df = pd.read_csv('data/raw_data.csv')\n",
        "    df.fillna(0, inplace=True)\n",
        "    df['new_feature'] = df['feature_1'] * df['feature_2']\n",
        "    df.to_csv('data/preprocessed_data.csv', index=False)\n",
        "\n",
        "\n",
        "default_args = {\n",
        "    'owner': 'airflow',\n",
        "    'start_date': datetime(2023, 1, 1),\n",
        "    'retries': 1,\n",
        "}\n",
        "\n",
        "dag = DAG(\n",
        "    'data_preprocessing_pipeline',\n",
        "    default_args=default_args,\n",
        "    schedule_interval='@daily',\n",
        ")\n",
        "\n",
        "preprocess_task = PythonOperator(\n",
        "    task_id='preprocess_data',\n",
        "    python_callable=preprocess_data,\n",
        "    dag=dag,\n",
        ")\n",
        "\n",
        "preprocess_task"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2: Model Training with MLflow for Experiment Tracking**\n",
        "\n"
      ],
      "metadata": {
        "id": "W8RGYOzFwfAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLflow helps track experiments, log parameters and store models. Below is an example of training a model using scikit-learn and logging it with MLflow:"
      ],
      "metadata": {
        "id": "4OwRz_-BwjiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data/preprocessed_data.csv')\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "with mlflow.start_run():\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    mlflow.log_param(\"n_estimators\", 100)\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "    mlflow.sklearn.log_model(model, \"random_forest_model\")"
      ],
      "metadata": {
        "id": "KdE1D2Cpu9HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3: Model Deployment**"
      ],
      "metadata": {
        "id": "9Lgd8ml3yx4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the model is trained it can be deployed as a REST API using Flask and containerized with Docker.\n",
        "\n",
        "Flask API Code (app.py):"
      ],
      "metadata": {
        "id": "lvcd3YZ6y02m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "model = joblib.load('model/random_forest_model.pkl')\n",
        "\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    data = request.json\n",
        "    df = pd.DataFrame([data])\n",
        "    prediction = model.predict(df)\n",
        "    return jsonify({'prediction': int(prediction[0])})\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5000)"
      ],
      "metadata": {
        "id": "6mVL9s7wzK8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Njbi8_T-0psk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base image\n",
        "FROM python:3.8-slim\n",
        "\n",
        "# Set working directory\n",
        "WORKDIR /app\n",
        "\n",
        "# Install dependencies\n",
        "COPY requirements.txt requirements.txt\n",
        "RUN pip install -r requirements.txt\n",
        "\n",
        "# Copy application code\n",
        "COPY . .\n",
        "\n",
        "# Expose port\n",
        "EXPOSE 5000\n",
        "\n",
        "# Run the app\n",
        "CMD [\"python\", \"app.py\"]"
      ],
      "metadata": {
        "id": "RdZmQbUd0p81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4: Monitoring Model Performance with Prometheus and Grafana**"
      ],
      "metadata": {
        "id": "v8FhYxtJ04dr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prometheus collects metrics and Grafana visualizes them. Below is an example of setting up monitoring for model accuracy."
      ],
      "metadata": {
        "id": "RvGxyiux09UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global:\n",
        "  scrape_interval: 15s\n",
        "\n",
        "scrape_configs:\n",
        "  - job_name: 'ml_model'\n",
        "    static_configs:\n",
        "      - targets: ['localhost:8000']"
      ],
      "metadata": {
        "id": "d40nHjU71ZaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export Metrics with Flask:"
      ],
      "metadata": {
        "id": "evMzKvV31nMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask\n",
        "from prometheus_client import start_http_server, Counter\n",
        "\n",
        "app = Flask(__name__)\n",
        "REQUESTS = Counter('http_requests_total', 'Total HTTP Requests')\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    REQUESTS.inc()\n",
        "    return \"Hello, World!\"\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    start_http_server(8000)\n",
        "    app.run(port=5000)"
      ],
      "metadata": {
        "id": "kdgljSX11ouR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Prometheus and Grafana locally using Docker Compose:"
      ],
      "metadata": {
        "id": "oHWRtch-1xCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "version: '3'\n",
        "services:\n",
        "  prometheus:\n",
        "    image: prom/prometheus\n",
        "    volumes:\n",
        "      - ./prometheus.yml:/etc/prometheus/prometheus.yml\n",
        "    ports:\n",
        "      - \"9090:9090\"\n",
        "  grafana:\n",
        "    image: grafana/grafana\n",
        "    ports:\n",
        "      - \"3000:3000\""
      ],
      "metadata": {
        "id": "anHLW0Eo17YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Feedback and Iteration**"
      ],
      "metadata": {
        "id": "dD2zg01L2Dpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, Query\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "model_a = joblib.load('model/model_a.pkl')\n",
        "model_b = joblib.load('model/model_b.pkl')\n",
        "\n",
        "\n",
        "@app.post(\"/predict/\")\n",
        "async def predict(features: dict, model_version: str = Query(..., enum=[\"A\", \"B\"])):\n",
        "    df = pd.DataFrame([features])\n",
        "    if model_version == \"A\":\n",
        "        prediction = model_a.predict(df)\n",
        "    elif model_version == \"B\":\n",
        "        prediction = model_b.predict(df)\n",
        "    return {\"model_version\": model_version, \"prediction\": int(prediction[0])}"
      ],
      "metadata": {
        "id": "2iUA8z6l1wXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TbEnZUws2K9j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}