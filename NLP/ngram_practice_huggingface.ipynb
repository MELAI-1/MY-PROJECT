{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNtdUVw2lgTS"
      },
      "source": [
        "# N-gram Language Models - Practice with Real Data\n",
        "\n",
        "**Course:** Natural Language Processing  \n",
        "**Topic:** Building N-gram Models with HuggingFace Datasets  \n",
        "\n",
        "In this notebook, you will:\n",
        "1. Load real text corpora from HuggingFace\n",
        "2. Implement n-gram language models from scratch\n",
        "3. Train and evaluate your models\n",
        "4. Generate text and compare different approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYaIDChtlgTT"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K22_18YxlgTU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install datasets -q\n",
        "\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Dict, Tuple\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "print(\"✓ Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDkkM--7lgTW"
      },
      "source": [
        "## Part 1: Load Dataset from HuggingFace\n",
        "\n",
        "We'll use the **WikiText-2** dataset, which contains good quality text from Wikipedia articles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7EvRIVTylgTW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading WikiText-2 dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70008b68c25749a1a4bcbdec5d0a1ef8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b43ac9e67ffb4c16856ab267f2425490",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "wikitext-2-raw-v1/test-00000-of-00001.pa(…):   0%|          | 0.00/733k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e88bc6af1f74dfb933eeaeca1f9b925",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "wikitext-2-raw-v1/train-00000-of-00001.p(…):   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81a827e157e247349220fe9c79f2beb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "wikitext-2-raw-v1/validation-00000-of-00(…):   0%|          | 0.00/657k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1728e26d199408191befca44d42cd91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11e0aad53d0a4f0ca44526ad144b15cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09ea70c2a6f847778255fdb5a88769cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset structure:\n",
            "DatasetDict({\n",
            "    test: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 4358\n",
            "    })\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 36718\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3760\n",
            "    })\n",
            "})\n",
            "\n",
            "Sample from training set:\n",
            "{'text': ''}\n",
            "\n",
            "============================================================\n",
            "{'text': ' = Valkyria Chronicles III = \\n'}\n"
          ]
        }
      ],
      "source": [
        "# Load WikiText-2 dataset\n",
        "print(\"Loading WikiText-2 dataset...\")\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
        "\n",
        "print(\"\\nDataset structure:\")\n",
        "print(dataset)\n",
        "\n",
        "# Explore the data\n",
        "print(\"\\nSample from training set:\")\n",
        "print(dataset['train'][0])\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(dataset['train'][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuuVYfEglgTX"
      },
      "source": [
        "### Exercise 1.1: Data Exploration\n",
        "\n",
        "Answer these questions:\n",
        "1. How many examples are in train/validation/test splits?\n",
        "2. What does each example look like?\n",
        "3. How many empty or very short texts are there?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'text': ['', ' = Valkyria Chronicles III = \\n', '', ' Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \\n', \" The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \\n\"]}\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g0LBrR70lgTX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 36718\n",
            "Validation size: 3760\n",
            "Test size: 4358\n",
            "\n",
            "First 5 examples from training set:\n",
            "{'text': ['', ' = Valkyria Chronicles III = \\n', '', ' Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \\n', \" The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \\n\"]}\n",
            "\n",
            "Checking for empty or short texts:\n",
            "Number of empty texts: 12951\n",
            "Number of short texts (<5 words): 13689\n"
          ]
        }
      ],
      "source": [
        "# Question 1: Count examples in each split\n",
        "train_size = len(dataset['train'])\n",
        "valid_size = len(dataset['validation'])\n",
        "test_size = len(dataset['test'])\n",
        "\n",
        "print(f\"Train size: {train_size}\")\n",
        "print(f\"Validation size: {valid_size}\")\n",
        "print(f\"Test size: {test_size}\")\n",
        "\n",
        "# Question 2: Look at a few examples\n",
        "print(\"\\nFirst 5 examples from training set:\")\n",
        "# TODO: YOUR CODE HERE - print first 5 examples\n",
        "print(dataset['train'][:5])\n",
        "\n",
        "\n",
        "# Question 3: Check for empty/short texts\n",
        "print(\"\\nChecking for empty or short texts:\")\n",
        "# TODO: YOUR CODE HERE - count texts with length 0 or < 5 words\n",
        "# Hint: Use len(text['text'].split())\n",
        "empty_count = sum(1 for text in dataset['train'] if len(text['text'].split()) == 0)\n",
        "short_count = sum(1 for text in dataset['train'] if len(text['text'].split()) < 5)\n",
        "print(f\"Number of empty texts: {empty_count}\")\n",
        "print(f\"Number of short texts (<5 words): {short_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv6iodXClgTY"
      },
      "source": [
        "## Part 2: Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPim9Of8lgTY"
      },
      "source": [
        "### Exercise 2.1: Implement Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ijOl_1CxlgTY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Hello World! This is a test.\n",
            "Expected: ['<s>', 'hello', 'world!', 'this', 'is', 'a', 'test.', '</s>']\n",
            "Your output: ['<s>', 'hello', 'world!', 'this', 'is', 'a', 'test.', '</s>']\n"
          ]
        }
      ],
      "source": [
        "def preprocess_text(text: str, add_start_end: bool = True) -> List[str]:\n",
        "    \"\"\"\n",
        "    Preprocess text:\n",
        "    - Convert to lowercase\n",
        "    - Split into tokens (simple whitespace tokenization)\n",
        "    - Add <s> and </s> tokens if requested\n",
        "\n",
        "    Args:\n",
        "        text: Input text\n",
        "        add_start_end: Whether to add start/end tokens\n",
        "\n",
        "    Returns:\n",
        "        List of tokens\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # Step 1: Convert to lowercase\n",
        "    text= text.lower()\n",
        "\n",
        "    # Step 2: Split on whitespace\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Step 3: Add <s> and </s> if requested\n",
        "    if add_start_end:\n",
        "        tokens = ['<s>'] + tokens + ['</s>']\n",
        "        return tokens\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "# Test your function\n",
        "test_text = \"Hello World! This is a test.\"\n",
        "tokens = preprocess_text(test_text, add_start_end=True)\n",
        "print(f\"Input: {test_text}\")\n",
        "print(f\"Expected: ['<s>', 'hello', 'world!', 'this', 'is', 'a', 'test.', '</s>']\")\n",
        "print(f\"Your output: {tokens}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXomFsnDlgTY"
      },
      "source": [
        "### Exercise 2.2: Prepare Training Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eqX3iMwwlgTZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing training corpus...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing:   4%|▍         | 1538/36718 [00:00<00:01, 17777.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Corpus size: 1000 sentences\n",
            "First sentence: ['<s>', '=', 'valkyria', 'chronicles', 'iii', '=', '</s>']...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def prepare_corpus(dataset_split, max_examples: int = None) -> List[List[str]]:\n",
        "    \"\"\"\n",
        "    Prepare corpus from dataset split.\n",
        "\n",
        "    Args:\n",
        "        dataset_split: HuggingFace dataset split\n",
        "        max_examples: Maximum number of examples to use (None = all)\n",
        "\n",
        "    Returns:\n",
        "        List of tokenized sentences\n",
        "    \"\"\"\n",
        "    corpus = []\n",
        "\n",
        "    # TODO: Implement this function\n",
        "    # 1. Iterate through the dataset\n",
        "    # 2. Skip empty texts (text['text'].strip() == '')\n",
        "    # 3. Preprocess each text using your function above\n",
        "    # 4. Add to corpus only if result has more than 2 tokens\n",
        "    # 5. Stop at max_examples if specified\n",
        "\n",
        "    # Hint: Use this structure:\n",
        "    # count = 0\n",
        "    # for item in tqdm(dataset_split, desc=\"Processing\"):\n",
        "    #     text = item['text'].strip()\n",
        "    #     if not text:\n",
        "    #         continue\n",
        "    #     ...\n",
        "    count = 0\n",
        "    for item in tqdm(dataset_split, desc=\"Processing\"):\n",
        "        text = item['text'].strip()\n",
        "        if not text:\n",
        "            continue\n",
        "        tokens = preprocess_text(text, add_start_end=True)\n",
        "        if len(tokens) > 2:\n",
        "            corpus.append(tokens)\n",
        "            count += 1\n",
        "        if max_examples and count >= max_examples:\n",
        "            break\n",
        "    return corpus\n",
        "\n",
        "    pass\n",
        "\n",
        "# Prepare training corpus (use subset for speed)\n",
        "print(\"Preparing training corpus...\")\n",
        "train_corpus = prepare_corpus(dataset['train'], max_examples=1000)\n",
        "\n",
        "print(f\"\\nCorpus size: {len(train_corpus)} sentences\")\n",
        "print(f\"First sentence: {train_corpus[0][:10]}...\")  # Show first 10 tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51GvsD2flgTZ"
      },
      "source": [
        "## Part 3: Build Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIfAPKJklgTZ"
      },
      "source": [
        "### Exercise 3.1: Build Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hJv1uLudlgTa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 10690\n",
            "Sample words: ['score', 'seller', 'q.', 'maat', 'calibers', 'symbolize', 'gigs', 'intervals', 'tertiary', 'andrews', 'qualified', 'emotional', 'constrained', 'way', 'decked', 'insurance', 'parliament', 'engage', 'trial', 'marines']\n"
          ]
        }
      ],
      "source": [
        "def build_vocabulary(corpus: List[List[str]]) -> set:\n",
        "    \"\"\"\n",
        "    Build vocabulary from corpus.\n",
        "\n",
        "    Args:\n",
        "        corpus: List of tokenized sentences\n",
        "\n",
        "    Returns:\n",
        "        Set of unique tokens\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # Hint: Create a set and add all tokens from all sentences\n",
        "    vocab = set()\n",
        "    for sentence in corpus:\n",
        "        for token in sentence:\n",
        "            vocab.add(token)\n",
        "    return vocab\n",
        "\n",
        "    pass\n",
        "\n",
        "# Build vocabulary\n",
        "vocab = build_vocabulary(train_corpus)\n",
        "print(f\"Vocabulary size: {len(vocab)}\")\n",
        "print(f\"Sample words: {list(vocab)[:20]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umCci2B3lgTa"
      },
      "source": [
        "## Part 4: Implement N-gram Counting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCizRaYzlgTa"
      },
      "source": [
        "### Exercise 4.1: Count Unigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "h5Nuo38QlgTa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unigrams: 90023\n",
            "Unique unigrams: 10690\n",
            "\n",
            "Most common unigrams:\n",
            "[('the', 5757), (',', 4468), ('.', 3203), ('of', 2568), ('and', 2237), ('in', 1927), ('to', 1655), ('a', 1574), ('=', 1191), ('<s>', 1000), ('</s>', 1000), ('\"', 961), ('was', 865), ('@-@', 782), ('with', 697), ('as', 663), ('for', 662), ('that', 623), (\"'s\", 606), ('on', 594)]\n"
          ]
        }
      ],
      "source": [
        "def count_unigrams(corpus: List[List[str]]) -> Counter:\n",
        "    \"\"\"\n",
        "    Count unigram frequencies.\n",
        "\n",
        "    Args:\n",
        "        corpus: List of tokenized sentences\n",
        "\n",
        "    Returns:\n",
        "        Counter with unigram counts\n",
        "    \"\"\"\n",
        "    unigram_counts = Counter()\n",
        "\n",
        "    # TODO: Implement this function\n",
        "    # Iterate through corpus and count each token\n",
        "    for sentence in corpus:\n",
        "        for token in sentence:\n",
        "            unigram_counts[token] += 1\n",
        "    return unigram_counts\n",
        "\n",
        "    pass\n",
        "\n",
        "# Test\n",
        "unigram_counts = count_unigrams(train_corpus)\n",
        "print(f\"Total unigrams: {sum(unigram_counts.values())}\")\n",
        "print(f\"Unique unigrams: {len(unigram_counts)}\")\n",
        "print(f\"\\nMost common unigrams:\")\n",
        "print(unigram_counts.most_common(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGgryfsClgTb"
      },
      "source": [
        "### Exercise 4.2: Count Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lnfI65Y_lgTb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total bigrams: 89023\n",
            "Unique bigrams: 50573\n",
            "\n",
            "Most common bigrams:\n",
            "[(('of', 'the'), 837), (('=', '='), 656), ((',', 'and'), 607), (('.', '</s>'), 578), (('.', 'the'), 526), (('in', 'the'), 498), ((',', 'the'), 316), (('to', 'the'), 268), (('<s>', '='), 264), (('=', '</s>'), 264), (('on', 'the'), 199), (('<s>', 'the'), 181), (('for', 'the'), 178), (('and', 'the'), 177), (('with', 'the'), 170), (('at', 'the'), 157), (('.', 'in'), 156), (('.', '\"'), 130), ((',', 'a'), 127), ((',', 'which'), 124)]\n"
          ]
        }
      ],
      "source": [
        "def count_bigrams(corpus: List[List[str]]) -> Counter:\n",
        "    \"\"\"\n",
        "    Count bigram frequencies.\n",
        "\n",
        "    Args:\n",
        "        corpus: List of tokenized sentences\n",
        "\n",
        "    Returns:\n",
        "        Counter with bigram counts (bigrams as tuples)\n",
        "    \"\"\"\n",
        "    bigram_counts = Counter()\n",
        "\n",
        "    # TODO: Implement this function\n",
        "    # For each sentence, create pairs of consecutive words\n",
        "    # Store as tuples: (word1, word2)\n",
        "    for sentence in corpus:\n",
        "        for i in range(len(sentence) - 1):\n",
        "            bigram = (sentence[i], sentence[i + 1])\n",
        "            bigram_counts[bigram] += 1\n",
        "    return bigram_counts\n",
        "\n",
        "    pass\n",
        "\n",
        "# Test\n",
        "bigram_counts = count_bigrams(train_corpus)\n",
        "print(f\"Total bigrams: {sum(bigram_counts.values())}\")\n",
        "print(f\"Unique bigrams: {len(bigram_counts)}\")\n",
        "print(f\"\\nMost common bigrams:\")\n",
        "print(bigram_counts.most_common(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeeilYfKlgTb"
      },
      "source": [
        "### Exercise 4.3: Count Trigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jjJEcv8-lgTc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total trigrams: 88023\n",
            "Unique trigrams: 76398\n",
            "\n",
            "Most common trigrams:\n",
            "[(('<s>', '=', '='), 230), (('=', '=', '</s>'), 230), (('=', '=', '='), 196), ((',', 'and', 'the'), 65), (('the', 'blue', 'jackets'), 39), (('one', 'of', 'the'), 37), (('.', '\"', '</s>'), 34), ((';', 'blackie', ','), 30), (('as', 'well', 'as'), 29), (('\"', '.', '</s>'), 27), ((',', 'such', 'as'), 27), (('the', 'gold', 'dollar'), 27), (('strapping', 'young', 'lad'), 26), (('the', 'united', 'states'), 25), (('.', 'she', 'was'), 24), (('.', 'it', 'was'), 22), ((',', 'and', 'a'), 22), (('.', 'in', 'the'), 22), (('south', 'of', 'heaven'), 22), (('in', 'the', 'uk'), 21)]\n"
          ]
        }
      ],
      "source": [
        "def count_trigrams(corpus: List[List[str]]) -> Counter:\n",
        "    \"\"\"\n",
        "    Count trigram frequencies.\n",
        "\n",
        "    Args:\n",
        "        corpus: List of tokenized sentences\n",
        "\n",
        "    Returns:\n",
        "        Counter with trigram counts (trigrams as tuples)\n",
        "    \"\"\"\n",
        "    trigram_counts = Counter()\n",
        "\n",
        "    # TODO: Implement this function\n",
        "    # For each sentence, create triples of consecutive words\n",
        "    # Store as tuples: (word1, word2, word3)\n",
        "    for sentence in corpus:\n",
        "        for i in range(len(sentence) - 2):\n",
        "            trigram = (sentence[i], sentence[i + 1], sentence[i + 2])\n",
        "            trigram_counts[trigram] += 1\n",
        "    return trigram_counts\n",
        "\n",
        "    pass\n",
        "\n",
        "# Test\n",
        "trigram_counts = count_trigrams(train_corpus)\n",
        "print(f\"Total trigrams: {sum(trigram_counts.values())}\")\n",
        "print(f\"Unique trigrams: {len(trigram_counts)}\")\n",
        "print(f\"\\nMost common trigrams:\")\n",
        "print(trigram_counts.most_common(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qinHVvZalgTc"
      },
      "source": [
        "## Part 5: Implement Language Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2NmRh5jlgTc"
      },
      "source": [
        "### Exercise 5.1: Unigram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ln6d9KAlgTd"
      },
      "outputs": [],
      "source": [
        "class UnigramModel:\n",
        "    \"\"\"Unigram language model.\"\"\"\n",
        "\n",
        "    def __init__(self, corpus: List[List[str]]):\n",
        "        self.unigram_counts = count_unigrams(corpus)\n",
        "        self.total_words = sum(self.unigram_counts.values())\n",
        "\n",
        "    def probability(self, word: str) -> float:\n",
        "        \"\"\"Calculate P(word).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # P(word) = C(word) / N\n",
        "        pass\n",
        "\n",
        "    def log_probability(self, word: str) -> float:\n",
        "        \"\"\"Calculate log P(word).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # Handle zero probability by returning float('-inf')\n",
        "        pass\n",
        "\n",
        "    def sentence_log_probability(self, sentence: List[str]) -> float:\n",
        "        \"\"\"Calculate log P(sentence).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # Sum of log probabilities of all words\n",
        "        pass\n",
        "\n",
        "# Test your model\n",
        "unigram_model = UnigramModel(train_corpus)\n",
        "test_words = [\"the\", \"of\", \"and\", \"<s>\", \"</s>\"]\n",
        "print(\"Unigram Probabilities:\")\n",
        "for word in test_words:\n",
        "    prob = unigram_model.probability(word)\n",
        "    print(f\"  P({word}) = {prob:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcDYvPszlgTd"
      },
      "source": [
        "### Exercise 5.2: Bigram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx8dfT3algTd"
      },
      "outputs": [],
      "source": [
        "class BigramModel:\n",
        "    \"\"\"Bigram language model.\"\"\"\n",
        "\n",
        "    def __init__(self, corpus: List[List[str]]):\n",
        "        self.unigram_counts = count_unigrams(corpus)\n",
        "        self.bigram_counts = count_bigrams(corpus)\n",
        "\n",
        "    def probability(self, word: str, previous_word: str) -> float:\n",
        "        \"\"\"Calculate P(word | previous_word).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # P(wi | wi-1) = C(wi-1, wi) / C(wi-1)\n",
        "        pass\n",
        "\n",
        "    def log_probability(self, word: str, previous_word: str) -> float:\n",
        "        \"\"\"Calculate log P(word | previous_word).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        pass\n",
        "\n",
        "    def sentence_log_probability(self, sentence: List[str]) -> float:\n",
        "        \"\"\"Calculate log P(sentence).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # Sum log probabilities: log P(w2|w1) + log P(w3|w2) + ...\n",
        "        pass\n",
        "\n",
        "# Test your model\n",
        "bigram_model = BigramModel(train_corpus)\n",
        "test_bigrams = [(\"<s>\", \"the\"), (\"the\", \"and\"), (\"of\", \"the\")]\n",
        "print(\"Bigram Probabilities:\")\n",
        "for w1, w2 in test_bigrams:\n",
        "    prob = bigram_model.probability(w2, w1)\n",
        "    print(f\"  P({w2} | {w1}) = {prob:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOt9aNrblgTe"
      },
      "source": [
        "### Exercise 5.3: Trigram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIj-y7vylgTe"
      },
      "outputs": [],
      "source": [
        "class TrigramModel:\n",
        "    \"\"\"Trigram language model.\"\"\"\n",
        "\n",
        "    def __init__(self, corpus: List[List[str]]):\n",
        "        self.bigram_counts = count_bigrams(corpus)\n",
        "        self.trigram_counts = count_trigrams(corpus)\n",
        "\n",
        "    def probability(self, word: str, prev_word1: str, prev_word2: str) -> float:\n",
        "        \"\"\"Calculate P(word | prev_word2, prev_word1).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # P(wi | wi-2, wi-1) = C(wi-2, wi-1, wi) / C(wi-2, wi-1)\n",
        "        pass\n",
        "\n",
        "    def log_probability(self, word: str, prev_word1: str, prev_word2: str) -> float:\n",
        "        \"\"\"Calculate log P(word | prev_word2, prev_word1).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        pass\n",
        "\n",
        "    def sentence_log_probability(self, sentence: List[str]) -> float:\n",
        "        \"\"\"Calculate log P(sentence).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        pass\n",
        "\n",
        "# Test your model\n",
        "trigram_model = TrigramModel(train_corpus)\n",
        "if len(train_corpus[0]) >= 3:\n",
        "    w1, w2, w3 = train_corpus[0][:3]\n",
        "    prob = trigram_model.probability(w3, w2, w1)\n",
        "    print(f\"P({w3} | {w1}, {w2}) = {prob:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFnvVRtolgTf"
      },
      "source": [
        "## Part 6: Model Evaluation - Perplexity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1muBDgElgTf"
      },
      "source": [
        "### Exercise 6.1: Implement Perplexity Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3wlxZHmlgTf"
      },
      "outputs": [],
      "source": [
        "def calculate_perplexity(model, test_corpus: List[List[str]], model_type: str = \"bigram\") -> float:\n",
        "    \"\"\"\n",
        "    Calculate perplexity for a language model.\n",
        "\n",
        "    Perplexity = exp(-1/N * sum(log P(wi | context)))\n",
        "\n",
        "    Args:\n",
        "        model: Language model with sentence_log_probability method\n",
        "        test_corpus: List of test sentences\n",
        "        model_type: 'unigram', 'bigram', or 'trigram'\n",
        "\n",
        "    Returns:\n",
        "        Perplexity score\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # 1. Calculate total log probability across all sentences\n",
        "    # 2. Count total words (excluding <s> for bigram/trigram)\n",
        "    # 3. Calculate average log probability\n",
        "    # 4. Return exp(-avg_log_prob)\n",
        "\n",
        "    pass\n",
        "\n",
        "# Prepare test corpus\n",
        "print(\"Preparing test corpus...\")\n",
        "test_corpus = prepare_corpus(dataset['validation'], max_examples=100)\n",
        "print(f\"Test corpus size: {len(test_corpus)} sentences\")\n",
        "\n",
        "# Calculate perplexities\n",
        "print(\"\\nCalculating perplexities...\")\n",
        "# TODO: Calculate and print perplexities for all three models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECg5LmJdlgTg"
      },
      "source": [
        "## Part 7: Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3pWw69elgTg"
      },
      "source": [
        "### Exercise 7.1: Implement Text Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5KPrY5nlgTh"
      },
      "outputs": [],
      "source": [
        "class BigramGenerator:\n",
        "    \"\"\"Generate text using bigram model.\"\"\"\n",
        "\n",
        "    def __init__(self, corpus: List[List[str]]):\n",
        "        self.bigram_model = BigramModel(corpus)\n",
        "        self.unigram_counts = count_unigrams(corpus)\n",
        "        self.bigram_counts = count_bigrams(corpus)\n",
        "        self.next_word_probs = self._build_next_word_distribution()\n",
        "\n",
        "    def _build_next_word_distribution(self) -> Dict:\n",
        "        \"\"\"Build distribution over next words for each word.\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # For each word w1, build dict of {w2: P(w2|w1)}\n",
        "        pass\n",
        "\n",
        "    def generate(self, max_length: int = 20) -> List[str]:\n",
        "        \"\"\"Generate a sentence.\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # 1. Start with '<s>'\n",
        "        # 2. Sample next word based on probabilities\n",
        "        # 3. Stop at '</s>' or max_length\n",
        "        # Hint: Use np.random.choice(words, p=probs)\n",
        "        pass\n",
        "\n",
        "# Test generator\n",
        "generator = BigramGenerator(train_corpus)\n",
        "print(\"Generated Sentences:\")\n",
        "print(\"=\" * 60)\n",
        "for i in range(10):\n",
        "    sentence = generator.generate(max_length=20)\n",
        "    print(f\"{i+1}. {' '.join(sentence)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu5ruTIHlgTh"
      },
      "source": [
        "## Part 8: Smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RoHApPilgTh"
      },
      "source": [
        "### Exercise 8.1: Implement Add-One Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDNAOGS5lgTi"
      },
      "outputs": [],
      "source": [
        "class BigramModelSmoothed:\n",
        "    \"\"\"Bigram model with add-one smoothing.\"\"\"\n",
        "\n",
        "    def __init__(self, corpus: List[List[str]]):\n",
        "        self.unigram_counts = count_unigrams(corpus)\n",
        "        self.bigram_counts = count_bigrams(corpus)\n",
        "        self.vocab = build_vocabulary(corpus)\n",
        "        self.vocab_size = len(self.vocab)\n",
        "\n",
        "    def probability(self, word: str, previous_word: str) -> float:\n",
        "        \"\"\"Calculate P(word | previous_word) with add-one smoothing.\n",
        "\n",
        "        Formula: P(wi | wi-1) = (C(wi-1, wi) + 1) / (C(wi-1) + V)\n",
        "        \"\"\"\n",
        "        # TODO: Implement this\n",
        "        pass\n",
        "\n",
        "    def log_probability(self, word: str, previous_word: str) -> float:\n",
        "        \"\"\"Calculate log P(word | previous_word).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        pass\n",
        "\n",
        "    def sentence_log_probability(self, sentence: List[str]) -> float:\n",
        "        \"\"\"Calculate log P(sentence).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        pass\n",
        "\n",
        "# Compare with unsmoothed model\n",
        "smoothed_model = BigramModelSmoothed(train_corpus)\n",
        "\n",
        "# Test on unseen bigrams\n",
        "test_unseen = [(\"<s>\", \"quantum\"), (\"the\", \"xylophone\"), (\"amazing\", \"unicorn\")]\n",
        "print(\"Comparison: Unsmoothed vs Smoothed\")\n",
        "print(\"=\" * 60)\n",
        "for w1, w2 in test_unseen:\n",
        "    unsmoothed = bigram_model.probability(w2, w1)\n",
        "    smoothed = smoothed_model.probability(w2, w1)\n",
        "    print(f\"P({w2} | {w1}):\")\n",
        "    print(f\"  Unsmoothed: {unsmoothed:.8f}\")\n",
        "    print(f\"  Smoothed:   {smoothed:.8f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQl9mrislgTi"
      },
      "source": [
        "## Part 9: Analysis and Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLR234yUlgTo"
      },
      "source": [
        "### Exercise 9.1: Compare All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxpgYZFelgTo"
      },
      "outputs": [],
      "source": [
        "# TODO: Create a comparison table showing:\n",
        "# 1. Number of parameters (unique n-grams)\n",
        "# 2. Training perplexity\n",
        "# 3. Test perplexity\n",
        "# 4. Sample generated sentences\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "comparison_data = {\n",
        "    'Model': ['Unigram', 'Bigram', 'Trigram', 'Bigram (Smoothed)'],\n",
        "    'Parameters': [\n",
        "        len(unigram_counts),\n",
        "        len(bigram_counts),\n",
        "        len(trigram_counts),\n",
        "        len(bigram_counts)\n",
        "    ],\n",
        "    'Train Perplexity': [\n",
        "        # TODO: Fill in\n",
        "        0.0, 0.0, 0.0, 0.0\n",
        "    ],\n",
        "    'Test Perplexity': [\n",
        "        # TODO: Fill in\n",
        "        0.0, 0.0, 0.0, 0.0\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(comparison_data)\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpNr6EIGlgTp"
      },
      "source": [
        "### Exercise 9.2: Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l3ekGgQlgTp"
      },
      "outputs": [],
      "source": [
        "# TODO: Create visualizations:\n",
        "# 1. Bar chart of perplexities\n",
        "# 2. Top-20 most common words\n",
        "# 3. Top-20 most common bigrams\n",
        "\n",
        "# Example for most common words:\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Most common unigrams\n",
        "# TODO: YOUR CODE HERE\n",
        "\n",
        "# Plot 2: Most common bigrams\n",
        "# TODO: YOUR CODE HERE\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8tjP5OWlgTp"
      },
      "source": [
        "## Part 10: Bonus Challenges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0qvnSfIlgTp"
      },
      "source": [
        "### Challenge 1: Try Different Datasets\n",
        "\n",
        "Load a different dataset from HuggingFace and train your models on it.\n",
        "\n",
        "Suggestions:\n",
        "- `\"wikitext\"` (different versions)\n",
        "- `\"bookcorpus\"`\n",
        "- `\"ptb_text_only\"` (Penn Treebank)\n",
        "- `\"imdb\"` (movie reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK5uI6P1lgTq"
      },
      "outputs": [],
      "source": [
        "# TODO: YOUR CODE HERE\n",
        "# Try loading and training on a different dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASmN7zBalgTq"
      },
      "source": [
        "### Challenge 2: Implement Better Smoothing\n",
        "\n",
        "Implement add-k smoothing (where k < 1) or interpolation smoothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUFk6cxflgTq"
      },
      "outputs": [],
      "source": [
        "# TODO: YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm2w_LlMlgTq"
      },
      "source": [
        "### Challenge 3: Build a Simple Autocomplete System\n",
        "\n",
        "Given a partial sentence, suggest the top-k most likely next words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6PQJPSolgTr"
      },
      "outputs": [],
      "source": [
        "def autocomplete(partial_sentence: str, model: BigramModel, k: int = 5) -> List[Tuple[str, float]]:\n",
        "    \"\"\"\n",
        "    Suggest next words for autocomplete.\n",
        "\n",
        "    Args:\n",
        "        partial_sentence: Incomplete sentence\n",
        "        model: Trained bigram model\n",
        "        k: Number of suggestions\n",
        "\n",
        "    Returns:\n",
        "        List of (word, probability) tuples\n",
        "    \"\"\"\n",
        "    # TODO: Implement this\n",
        "    pass\n",
        "\n",
        "# Test\n",
        "test_partial = \"the cat sat on the\"\n",
        "suggestions = autocomplete(test_partial, bigram_model, k=5)\n",
        "print(f\"Suggestions for: '{test_partial}'\")\n",
        "for word, prob in suggestions:\n",
        "    print(f\"  {word}: {prob:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
