{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNtdUVw2lgTS"
      },
      "source": [
        "# N-gram Language Models - Practice with Real Data\n",
        "\n",
        "**Course:** Natural Language Processing  \n",
        "**Topic:** Building N-gram Models with HuggingFace Datasets  \n",
        "\n",
        "In this notebook, you will:\n",
        "1. Load real text corpora from HuggingFace\n",
        "2. Implement n-gram language models from scratch\n",
        "3. Train and evaluate your models\n",
        "4. Generate text and compare different approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYaIDChtlgTT"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K22_18YxlgTU"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install datasets -q\n",
        "\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Dict, Tuple\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "print(\"âœ“ Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDkkM--7lgTW"
      },
      "source": [
        "## Part 1: Load Dataset from HuggingFace\n",
        "\n",
        "We'll use the **WikiText-2** dataset, which contains good quality text from Wikipedia articles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EvRIVTylgTW"
      },
      "outputs": [],
      "source": [
        "# Load WikiText-2 dataset\n",
        "print(\"Loading WikiText-2 dataset...\")\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
        "\n",
        "print(\"\\nDataset structure:\")\n",
        "print(dataset)\n",
        "\n",
        "# Explore the data\n",
        "print(\"\\nSample from training set:\")\n",
        "print(dataset['train'][0])\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(dataset['train'][1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuuVYfEglgTX"
      },
      "source": [
        "### Exercise 1.1: Data Exploration\n",
        "\n",
        "Answer these questions:\n",
        "1. How many examples are in train/validation/test splits?\n",
        "2. What does each example look like?\n",
        "3. How many empty or very short texts are there?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0LBrR70lgTX"
      },
      "outputs": [],
      "source": [
        "# Question 1: Count examples in each split\n",
        "train_size = len(dataset['train'])\n",
        "valid_size = len(dataset['validation'])\n",
        "test_size = len(dataset['test'])\n",
        "\n",
        "print(f\"Train size: {train_size}\")\n",
        "print(f\"Validation size: {valid_size}\")\n",
        "print(f\"Test size: {test_size}\")\n",
        "\n",
        "# Question 2: Look at a few examples\n",
        "print(\"\\nFirst 5 examples from training set:\")\n",
        "# TODO: YOUR CODE HERE - print first 5 examples\n",
        "print(dataset['train'][:5])\n",
        "\n",
        "\n",
        "# Question 3: Check for empty/short texts\n",
        "print(\"\\nChecking for empty or short texts:\")\n",
        "# TODO: YOUR CODE HERE - count texts with length 0 or < 5 words\n",
        "# Hint: Use len(text['text'].split())\n",
        "empty_count = sum(1 for text in dataset['train'] if len(text['text'].split()) == 0)\n",
        "short_count = sum(1 for text in dataset['train'] if len(text['text'].split()) < 5)\n",
        "print(f\"Number of empty texts: {empty_count}\")\n",
        "print(f\"Number of short texts (<5 words): {short_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv6iodXClgTY"
      },
      "source": [
        "## Part 2: Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPim9Of8lgTY"
      },
      "source": [
        "### Exercise 2.1: Implement Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijOl_1CxlgTY"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text: str, add_start_end: bool = True) -> List[str]:\n",
        "    \"\"\"\n",
        "    Preprocess text:\n",
        "    - Convert to lowercase\n",
        "    - Split into tokens (simple whitespace tokenization)\n",
        "    - Add <s> and </s> tokens if requested\n",
        "\n",
        "    Args:\n",
        "        text: Input text\n",
        "        add_start_end: Whether to add start/end tokens\n",
        "\n",
        "    Returns:\n",
        "        List of tokens\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # Step 1: Convert to lowercase\n",
        "    text= text.lower()\n",
        "\n",
        "    # Step 2: Split on whitespace\n",
        "    tokens = text.split()\n",
        "\n",
        "    # Step 3: Add <s> and </s> if requested\n",
        "    if add_start_end:\n",
        "        tokens = ['<s>'] + tokens + ['</s>']\n",
        "        return tokens\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "# Test your function\n",
        "test_text = \"Hello World! This is a test.\"\n",
        "tokens = preprocess_text(test_text, add_start_end=True)\n",
        "print(f\"Input: {test_text}\")\n",
        "print(f\"Expected: ['<s>', 'hello', 'world!', 'this', 'is', 'a', 'test.', '</s>']\")\n",
        "print(f\"Your output: {tokens}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXomFsnDlgTY"
      },
      "source": [
        "### Exercise 2.2: Prepare Training Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqX3iMwwlgTZ"
      },
      "outputs": [],
      "source": [
        "def prepare_corpus(dataset_split, max_examples: int = None) -> List[List[str]]:\n",
        "    \"\"\"\n",
        "    Prepare corpus from dataset split.\n",
        "\n",
        "    Args:\n",
        "        dataset_split: HuggingFace dataset split\n",
        "        max_examples: Maximum number of examples to use (None = all)\n",
        "\n",
        "    Returns:\n",
        "        List of tokenized sentences\n",
        "    \"\"\"\n",
        "    corpus = []\n",
        "\n",
        "    # TODO: Implement this function\n",
        "    # 1. Iterate through the dataset\n",
        "    # 2. Skip empty texts (text['text'].strip() == '')\n",
        "    # 3. Preprocess each text using your function above\n",
        "    # 4. Add to corpus only if result has more than 2 tokens\n",
        "    # 5. Stop at max_examples if specified\n",
        "\n",
        "    # Hint: Use this structure:\n",
        "    # count = 0\n",
        "    # for item in tqdm(dataset_split, desc=\"Processing\"):\n",
        "    #     text = item['text'].strip()\n",
        "    #     if not text:\n",
        "    #         continue\n",
        "    #     ...\n",
        "    count = 0\n",
        "    for item in tqdm(dataset_split, desc=\"Processing\"):\n",
        "        text = item['text'].strip()\n",
        "        if not text:\n",
        "            continue\n",
        "        tokens = preprocess_text(text, add_start_end=True)\n",
        "        if len(tokens) > 2:\n",
        "            corpus.append(tokens)\n",
        "            count += 1\n",
        "        if max_examples and count >= max_examples:\n",
        "            break\n",
        "    return corpus\n",
        "\n",
        "    pass\n",
        "\n",
        "# Prepare training corpus (use subset for speed)\n",
        "print(\"Preparing training corpus...\")\n",
        "train_corpus = prepare_corpus(dataset['train'], max_examples=1000)\n",
        "\n",
        "print(f\"\\nCorpus size: {len(train_corpus)} sentences\")\n",
        "print(f\"First sentence: {train_corpus[0][:10]}...\")  # Show first 10 tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51GvsD2flgTZ"
      },
      "source": [
        "## Part 3: Build Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIfAPKJklgTZ"
      },
      "source": [
        "### Exercise 3.1: Build Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJv1uLudlgTa"
      },
      "outputs": [],
      "source": [
        "def build_vocabulary(corpus: List[List[str]]) -> set:\n",
        "    \"\"\"\n",
        "    Build vocabulary from corpus.\n",
        "\n",
        "    Args:\n",
        "        corpus: List of tokenized sentences\n",
        "\n",
        "    Returns:\n",
        "        Set of unique tokens\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # Hint: Create a set and add all tokens from all sentences\n",
        "    vocab = set()\n",
        "    for sentence in corpus:\n",
        "        for token in sentence:\n",
        "            vocab.add(token)\n",
        "    return vocab\n",
        "\n",
        "    pass\n",
        "\n",
        "# Build vocabulary\n",
        "vocab = build_vocabulary(train_corpus)\n",
        "print(f\"Vocabulary size: {len(vocab)}\")\n",
        "print(f\"Sample words: {list(vocab)[:20]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umCci2B3lgTa"
      },
      "source": [
        "## Part 4: Implement N-gram Counting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCizRaYzlgTa"
      },
      "source": [
        "### Exercise 4.1: Count Unigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5Nuo38QlgTa"
      },
      "outputs": [],
      "source": [
        "def count_unigrams(corpus: List[List[str]]) -> Counter:\n",
        "    \"\"\"\n",
        "    Count unigram frequencies.\n",
        "\n",
        "    Args:\n",
        "        corpus: List of tokenized sentences\n",
        "\n",
        "    Returns:\n",
        "        Counter with unigram counts\n",
        "    \"\"\"\n",
        "    unigram_counts = Counter()\n",
        "\n",
        "    # TODO: Implement this function\n",
        "    # Iterate through corpus and count each token\n",
        "    for sentence in corpus:\n",
        "        for token in sentence:\n",
        "            unigram_counts[token] += 1\n",
        "    return unigram_counts\n",
        "\n",
        "    pass\n",
        "\n",
        "# Test\n",
        "unigram_counts = count_unigrams(train_corpus)\n",
        "print(f\"Total unigrams: {sum(unigram_counts.values())}\")\n",
        "print(f\"Unique unigrams: {len(unigram_counts)}\")\n",
        "print(f\"\\nMost common unigrams:\")\n",
        "print(unigram_counts.most_common(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGgryfsClgTb"
      },
      "source": [
        "### Exercise 4.2: Count Bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnfI65Y_lgTb"
      },
      "outputs": [],
      "source": [
        "def count_bigrams(corpus: List[List[str]]) -> Counter:\n",
        "    \"\"\"\n",
        "    Count bigram frequencies.\n",
        "\n",
        "    Args:\n",
        "        corpus: List of tokenized sentences\n",
        "\n",
        "    Returns:\n",
        "        Counter with bigram counts (bigrams as tuples)\n",
        "    \"\"\"\n",
        "    bigram_counts = Counter()\n",
        "\n",
        "    # TODO: Implement this function\n",
        "    # For each sentence, create pairs of consecutive words\n",
        "    # Store as tuples: (word1, word2)\n",
        "    for sentence in corpus:\n",
        "        for i in range(len(sentence) - 1):\n",
        "            bigram = (sentence[i], sentence[i + 1])\n",
        "            bigram_counts[bigram] += 1\n",
        "    return bigram_counts\n",
        "\n",
        "    pass\n",
        "\n",
        "# Test\n",
        "bigram_counts = count_bigrams(train_corpus)\n",
        "print(f\"Total bigrams: {sum(bigram_counts.values())}\")\n",
        "print(f\"Unique bigrams: {len(bigram_counts)}\")\n",
        "print(f\"\\nMost common bigrams:\")\n",
        "print(bigram_counts.most_common(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeeilYfKlgTb"
      },
      "source": [
        "### Exercise 4.3: Count Trigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjJEcv8-lgTc"
      },
      "outputs": [],
      "source": [
        "def count_trigrams(corpus: List[List[str]]) -> Counter:\n",
        "    \"\"\"\n",
        "    Count trigram frequencies.\n",
        "\n",
        "    Args:\n",
        "        corpus: List of tokenized sentences\n",
        "\n",
        "    Returns:\n",
        "        Counter with trigram counts (trigrams as tuples)\n",
        "    \"\"\"\n",
        "    trigram_counts = Counter()\n",
        "\n",
        "    # TODO: Implement this function\n",
        "    # For each sentence, create triples of consecutive words\n",
        "    # Store as tuples: (word1, word2, word3)\n",
        "    for sentence in corpus:\n",
        "        for i in range(len(sentence) - 2):\n",
        "            trigram = (sentence[i], sentence[i + 1], sentence[i + 2])\n",
        "            trigram_counts[trigram] += 1\n",
        "    return trigram_counts\n",
        "\n",
        "    pass\n",
        "\n",
        "# Test\n",
        "trigram_counts = count_trigrams(train_corpus)\n",
        "print(f\"Total trigrams: {sum(trigram_counts.values())}\")\n",
        "print(f\"Unique trigrams: {len(trigram_counts)}\")\n",
        "print(f\"\\nMost common trigrams:\")\n",
        "print(trigram_counts.most_common(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qinHVvZalgTc"
      },
      "source": [
        "## Part 5: Implement Language Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2NmRh5jlgTc"
      },
      "source": [
        "### Exercise 5.1: Unigram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ln6d9KAlgTd"
      },
      "outputs": [],
      "source": [
        "class UnigramModel:\n",
        "    \"\"\"Unigram language model.\"\"\"\n",
        "\n",
        "    def __init__(self, corpus: List[List[str]]):\n",
        "        self.unigram_counts = count_unigrams(corpus)\n",
        "        self.total_words = sum(self.unigram_counts.values())\n",
        "\n",
        "    def probability(self, word: str) -> float:\n",
        "        \"\"\"Calculate P(word).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # P(word) = C(word) / N\n",
        "        prob = self.unigram_counts[word] / self.total_words if self.total_words > 0 else 0.0\n",
        "        return prob\n",
        "        pass\n",
        "\n",
        "    def log_probability(self, word: str) -> float:\n",
        "        \"\"\"Calculate log P(word).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # Handle zero probability by returning float('-inf')\n",
        "        prob = self.probability(word)\n",
        "        if prob > 0:\n",
        "            return np.log(prob)\n",
        "        else:\n",
        "            return float('-inf')\n",
        "        pass\n",
        "\n",
        "    def sentence_log_probability(self, sentence: List[str]) -> float:\n",
        "        \"\"\"Calculate log P(sentence).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # Sum of log probabilities of all words\n",
        "        sum_log_prob = 0.0\n",
        "        for word in sentence:\n",
        "            sum_log_prob += self.log_probability(word)\n",
        "        return sum_log_prob\n",
        "        pass\n",
        "\n",
        "# Test your model\n",
        "unigram_model = UnigramModel(train_corpus)\n",
        "test_words = [\"the\", \"of\", \"and\", \"<s>\", \"</s>\"]\n",
        "print(\"Unigram Probabilities:\")\n",
        "for word in test_words:\n",
        "    prob = unigram_model.probability(word)\n",
        "    print(f\"  P({word}) = {prob:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcDYvPszlgTd"
      },
      "source": [
        "### Exercise 5.2: Bigram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx8dfT3algTd"
      },
      "outputs": [],
      "source": [
        "class BigramModel:\n",
        "    \"\"\"Bigram language model.\"\"\"\n",
        "\n",
        "    def __init__(self, corpus: List[List[str]]):\n",
        "        self.unigram_counts = count_unigrams(corpus)\n",
        "        self.bigram_counts = count_bigrams(corpus)\n",
        "\n",
        "    def probability(self, word: str, previous_word: str) -> float:\n",
        "        \"\"\"Calculate P(word | previous_word).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # P(wi | wi-1) = C(wi-1, wi) / C(wi-1)\n",
        "        prob=self.bigram_counts[(previous_word, word)] / self.unigram_counts[previous_word] if self.unigram_counts[previous_word] > 0 else 0.0\n",
        "        return prob\n",
        "        pass\n",
        "\n",
        "    def log_probability(self, word: str, previous_word: str) -> float:\n",
        "        \"\"\"Calculate log P(word | previous_word).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        prob = self.probability(word, previous_word)\n",
        "        if prob > 0:\n",
        "            return np.log(prob)\n",
        "        else:\n",
        "            return float('-inf')\n",
        "        pass\n",
        "\n",
        "    def sentence_log_probability(self, sentence: List[str]) -> float:\n",
        "        \"\"\"Calculate log P(sentence).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # Sum log probabilities: log P(w2|w1) + log P(w3|w2) + ...\n",
        "        sum_log_prob = 0.0\n",
        "        for i in range(1, len(sentence)):\n",
        "            prev_word = sentence[i - 1]\n",
        "            word = sentence[i]\n",
        "            sum_log_prob += self.log_probability(word, prev_word)\n",
        "        return sum_log_prob\n",
        "        pass\n",
        "\n",
        "# Test your model\n",
        "bigram_model = BigramModel(train_corpus)\n",
        "test_bigrams = [(\"<s>\", \"the\"), (\"the\", \"and\"), (\"of\", \"the\")]\n",
        "print(\"Bigram Probabilities:\")\n",
        "for w1, w2 in test_bigrams:\n",
        "    prob = bigram_model.probability(w2, w1)\n",
        "    print(f\"  P({w2} | {w1}) = {prob:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOt9aNrblgTe"
      },
      "source": [
        "### Exercise 5.3: Trigram Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIj-y7vylgTe"
      },
      "outputs": [],
      "source": [
        "class TrigramModel:\n",
        "    \"\"\"Trigram language model.\"\"\"\n",
        "\n",
        "    def __init__(self, corpus: List[List[str]]):\n",
        "        self.bigram_counts = count_bigrams(corpus)\n",
        "        self.trigram_counts = count_trigrams(corpus)\n",
        "\n",
        "    def probability(self, word: str, prev_word1: str, prev_word2: str) -> float:\n",
        "        \"\"\"Calculate P(word | prev_word2, prev_word1).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # P(wi | wi-2, wi-1) = C(wi-2, wi-1, wi) / C(wi-2, wi-1)\n",
        "        prob=self.trigram_counts[(prev_word2, prev_word1, word)] / self.bigram_counts[(prev_word2, prev_word1)] if self.bigram_counts[(prev_word2, prev_word1)] > 0 else 0.0\n",
        "        return prob\n",
        "        pass\n",
        "\n",
        "    def log_probability(self, word: str, prev_word1: str, prev_word2: str) -> float:\n",
        "        \"\"\"Calculate log P(word | prev_word2, prev_word1).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        prob = self.probability(word, prev_word1, prev_word2)\n",
        "        if prob > 0:\n",
        "            return np.log(prob)\n",
        "        else:\n",
        "            return float('-inf')\n",
        "        pass\n",
        "\n",
        "    def sentence_log_probability(self, sentence: List[str]) -> float:\n",
        "        \"\"\"Calculate log P(sentence).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # Sum log probabilities: log P(w3|w1,w2) + log P(w4|w2,w3) + ...\n",
        "        sum_log_prob = 0.0\n",
        "        for i in range(2, len(sentence)):\n",
        "            prev_word2 = sentence[i - 2]\n",
        "            prev_word1 = sentence[i - 1]\n",
        "            word = sentence[i]\n",
        "            sum_log_prob += self.log_probability(word, prev_word1, prev_word2)\n",
        "        return sum_log_prob\n",
        "        pass\n",
        "\n",
        "# Test your model\n",
        "trigram_model = TrigramModel(train_corpus)\n",
        "if len(train_corpus[0]) >= 3:\n",
        "    w1, w2, w3 = train_corpus[0][:3]\n",
        "    prob = trigram_model.probability(w3, w2, w1)\n",
        "    print(f\"P({w3} | {w1}, {w2}) = {prob:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFnvVRtolgTf"
      },
      "source": [
        "## Part 6: Model Evaluation - Perplexity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1muBDgElgTf"
      },
      "source": [
        "### Exercise 6.1: Implement Perplexity Calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3wlxZHmlgTf"
      },
      "outputs": [],
      "source": [
        "def calculate_perplexity(model, test_corpus: List[List[str]], model_type: str = \"bigram\") -> float:\n",
        "    \"\"\"\n",
        "    Calculate perplexity for a language model.\n",
        "\n",
        "    Perplexity = exp(-1/N * sum(log P(wi | context)))\n",
        "\n",
        "    Args:\n",
        "        model: Language model with sentence_log_probability method\n",
        "        test_corpus: List of test sentences\n",
        "        model_type: 'unigram', 'bigram', or 'trigram'\n",
        "\n",
        "    Returns:\n",
        "        Perplexity score\n",
        "    \"\"\"\n",
        "    # TODO: Implement this function\n",
        "    # 1. Calculate total log probability across all sentences\n",
        "    # 2. Count total words (excluding <s> for unigram, and context tokens)\n",
        "    # 3. Calculate average log probability\n",
        "    # 4. Return exp(-avg_log_prob)\n",
        "    sum_log_prob = 0.0\n",
        "    total_words = 0 \n",
        "    \n",
        "    for sentence in test_corpus:\n",
        "        log_prob = model.sentence_log_probability(sentence)\n",
        "        sum_log_prob += log_prob\n",
        "        \n",
        "        if model_type == \"unigram\":\n",
        "            # For unigram, count all tokens including <s> and </s>\n",
        "            total_words += len(sentence)\n",
        "        elif model_type == \"bigram\":\n",
        "            # For bigram, we count pairs starting from position 1\n",
        "            # P(w1|w0) + P(w2|w1) + ... so we have len-1 predictions\n",
        "            total_words += len(sentence) - 1  \n",
        "        elif model_type == \"trigram\":\n",
        "            # For trigram, we count triples starting from position 2\n",
        "            # P(w2|w0,w1) + P(w3|w1,w2) + ... so we have len-2 predictions\n",
        "            total_words += len(sentence) - 2\n",
        "    \n",
        "    if total_words == 0:\n",
        "        return float('inf')\n",
        "    \n",
        "    # Average log probability (this will be negative)\n",
        "    avg_log_prob = sum_log_prob / total_words\n",
        "    \n",
        "    # Perplexity = exp(-avg_log_prob) = exp(|avg_log_prob|) since avg_log_prob is negative\n",
        "    perplexity = np.exp(-avg_log_prob)\n",
        "    \n",
        "    return perplexity\n",
        "\n",
        "# Prepare test corpus\n",
        "print(\"Preparing test corpus...\")\n",
        "test_corpus = prepare_corpus(dataset['validation'], max_examples=100)\n",
        "print(f\"Test corpus size: {len(test_corpus)} sentences\")\n",
        "\n",
        "# Calculate perplexities\n",
        "print(\"\\nCalculating perplexities...\")\n",
        "# TODO: Calculate and print perplexities for all three models\n",
        "print(f\"Unigram Model Perplexity: {calculate_perplexity(unigram_model, test_corpus, model_type='unigram'):.2f}\")\n",
        "print(f\"Bigram Model Perplexity: {calculate_perplexity(bigram_model, test_corpus, model_type='bigram'):.2f}\")\n",
        "print(f\"Trigram Model Perplexity: {calculate_perplexity(trigram_model, test_corpus, model_type='trigram'):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECg5LmJdlgTg"
      },
      "source": [
        "## Part 7: Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3pWw69elgTg"
      },
      "source": [
        "### Exercise 7.1: Implement Text Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5KPrY5nlgTh"
      },
      "outputs": [],
      "source": [
        "class BigramGenerator:\n",
        "    \"\"\"Generate text using bigram model.\"\"\"\n",
        "\n",
        "    def __init__(self, corpus: List[List[str]]):\n",
        "        self.bigram_model = BigramModel(corpus)\n",
        "        self.unigram_counts = count_unigrams(corpus)\n",
        "        self.bigram_counts = count_bigrams(corpus)\n",
        "        self.next_word_probs = self._build_next_word_distribution()\n",
        "\n",
        "    def _build_next_word_distribution(self) -> Dict:\n",
        "        \"\"\"Build distribution over next words for each word.\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # For each word w1, build dict of {w2: P(w2|w1)}\n",
        "        self.next_word_probs = {}\n",
        "        for word1 in self.unigram_counts:\n",
        "            total_count = self.unigram_counts[word1]\n",
        "            next_words = {}\n",
        "            for word2 in self.unigram_counts:\n",
        "                bigram = (word1, word2)\n",
        "                count = self.bigram_counts[bigram]\n",
        "                if total_count > 0:\n",
        "                    next_words[word2] = count / total_count\n",
        "            self.next_word_probs[word1] = next_words\n",
        "        return self.next_word_probs\n",
        "\n",
        "    def generate(self, max_length: int = 20) -> List[str]:\n",
        "        \"\"\"Generate a sentence.\"\"\"\n",
        "        # TODO: Implement this\n",
        "        # 1. Start with '<s>'\n",
        "        # 2. Sample next word based on probabilities\n",
        "        # 3. Stop at '</s>' or max_length\n",
        "        # Hint: Use np.random.choice(words, p=probs)\n",
        "        sentence = ['<s>']\n",
        "        \n",
        "        for _ in range(max_length - 1):\n",
        "            current_word = sentence[-1]\n",
        "            \n",
        "            # Get next word probabilities\n",
        "            if current_word not in self.next_word_probs:\n",
        "                break\n",
        "            \n",
        "            next_word_dict = self.next_word_probs[current_word]\n",
        "            if not next_word_dict:\n",
        "                break\n",
        "            \n",
        "            # Prepare words and probabilities\n",
        "            words = list(next_word_dict.keys())\n",
        "            probs = np.array(list(next_word_dict.values()))\n",
        "            \n",
        "            # Normalize probabilities\n",
        "            probs = probs / np.sum(probs)\n",
        "            \n",
        "            # Sample next word\n",
        "            next_word = np.random.choice(words, p=probs)\n",
        "            sentence.append(next_word)\n",
        "            \n",
        "            # Stop if end token\n",
        "            if next_word == '</s>':\n",
        "                break\n",
        "        \n",
        "        return sentence\n",
        "\n",
        "# Test generator\n",
        "generator = BigramGenerator(train_corpus)\n",
        "print(\"Generated Sentences:\")\n",
        "print(\"=\" * 60)\n",
        "for i in range(10):\n",
        "    sentence = generator.generate(max_length=20)\n",
        "    print(f\"{i+1}. {' '.join(sentence)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu5ruTIHlgTh"
      },
      "source": [
        "## Part 8: Smoothing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RoHApPilgTh"
      },
      "source": [
        "### Exercise 8.1: Implement Add-One Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDNAOGS5lgTi"
      },
      "outputs": [],
      "source": [
        "class BigramModelSmoothed:\n",
        "    \"\"\"Bigram model with add-one smoothing.\"\"\"\n",
        "\n",
        "    def __init__(self, corpus: List[List[str]]):\n",
        "        self.unigram_counts = count_unigrams(corpus)\n",
        "        self.bigram_counts = count_bigrams(corpus)\n",
        "        self.vocab = build_vocabulary(corpus)\n",
        "        self.vocab_size = len(self.vocab)\n",
        "\n",
        "    def probability(self, word: str, previous_word: str) -> float:\n",
        "        \"\"\"Calculate P(word | previous_word) with add-one smoothing.\n",
        "\n",
        "        Formula: P(wi | wi-1) = (C(wi-1, wi) + 1) / (C(wi-1) + V)\n",
        "        \"\"\"\n",
        "        # TODO: Implement this\n",
        "        bigram = (previous_word, word)\n",
        "        count = self.bigram_counts[bigram]\n",
        "        prev_count = self.unigram_counts[previous_word]\n",
        "        \n",
        "        if prev_count > 0:\n",
        "            prob = (count + 1) / (prev_count + self.vocab_size)\n",
        "        else:\n",
        "            prob = 1.0 / self.vocab_size\n",
        "        \n",
        "        return prob\n",
        "\n",
        "    def log_probability(self, word: str, previous_word: str) -> float:\n",
        "        \"\"\"Calculate log P(word | previous_word).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        prob = self.probability(word, previous_word)\n",
        "        if prob > 0:\n",
        "            return np.log(prob)\n",
        "        else:\n",
        "            return float('-inf')\n",
        "\n",
        "    def sentence_log_probability(self, sentence: List[str]) -> float:\n",
        "        \"\"\"Calculate log P(sentence).\"\"\"\n",
        "        # TODO: Implement this\n",
        "        sum_log_prob = 0.0\n",
        "        for i in range(1, len(sentence)):\n",
        "            prev_word = sentence[i - 1]\n",
        "            word = sentence[i]\n",
        "            sum_log_prob += self.log_probability(word, prev_word)\n",
        "        return sum_log_prob\n",
        "\n",
        "# Compare with unsmoothed model\n",
        "smoothed_model = BigramModelSmoothed(train_corpus)\n",
        "\n",
        "# Test on unseen bigrams\n",
        "test_unseen = [(\"<s>\", \"quantum\"), (\"the\", \"xylophone\"), (\"amazing\", \"unicorn\")]\n",
        "print(\"Comparison: Unsmoothed vs Smoothed\")\n",
        "print(\"=\" * 60)\n",
        "for w1, w2 in test_unseen:\n",
        "    unsmoothed = bigram_model.probability(w2, w1)\n",
        "    smoothed = smoothed_model.probability(w2, w1)\n",
        "    print(f\"P({w2} | {w1}):\")\n",
        "    print(f\"  Unsmoothed: {unsmoothed:.8f}\")\n",
        "    print(f\"  Smoothed:   {smoothed:.8f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQl9mrislgTi"
      },
      "source": [
        "## Part 9: Analysis and Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLR234yUlgTo"
      },
      "source": [
        "### Exercise 9.1: Compare All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxpgYZFelgTo"
      },
      "outputs": [],
      "source": [
        "# TODO: Create a comparison table showing:\n",
        "# 1. Number of parameters (unique n-grams)\n",
        "# 2. Training perplexity\n",
        "# 3. Test perplexity\n",
        "# 4. Sample generated sentences\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Calculate training perplexities\n",
        "train_perplexity_unigram = calculate_perplexity(unigram_model, train_corpus, model_type='unigram')\n",
        "train_perplexity_bigram = calculate_perplexity(bigram_model, train_corpus, model_type='bigram')\n",
        "train_perplexity_trigram = calculate_perplexity(trigram_model, train_corpus, model_type='trigram')\n",
        "train_perplexity_smoothed = calculate_perplexity(smoothed_model, train_corpus, model_type='bigram')\n",
        "\n",
        "# Calculate test perplexities\n",
        "test_perplexity_unigram = calculate_perplexity(unigram_model, test_corpus, model_type='unigram')\n",
        "test_perplexity_bigram = calculate_perplexity(bigram_model, test_corpus, model_type='bigram')\n",
        "test_perplexity_trigram = calculate_perplexity(trigram_model, test_corpus, model_type='trigram')\n",
        "test_perplexity_smoothed = calculate_perplexity(smoothed_model, test_corpus, model_type='bigram')\n",
        "\n",
        "comparison_data = {\n",
        "    'Model': ['Unigram', 'Bigram', 'Trigram', 'Bigram (Smoothed)'],\n",
        "    'Parameters': [\n",
        "        len(unigram_counts),\n",
        "        len(bigram_counts),\n",
        "        len(trigram_counts),\n",
        "        len(bigram_counts)\n",
        "    ],\n",
        "    'Train Perplexity': [\n",
        "        train_perplexity_unigram,\n",
        "        train_perplexity_bigram,\n",
        "        train_perplexity_trigram,\n",
        "        train_perplexity_smoothed\n",
        "    ],\n",
        "    'Test Perplexity': [\n",
        "        test_perplexity_unigram,\n",
        "        test_perplexity_bigram,\n",
        "        test_perplexity_trigram,\n",
        "        test_perplexity_smoothed\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(comparison_data)\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpNr6EIGlgTp"
      },
      "source": [
        "### Exercise 9.2: Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l3ekGgQlgTp"
      },
      "outputs": [],
      "source": [
        "# TODO: Create visualizations:\n",
        "# 1. Bar chart of perplexities\n",
        "# 2. Top-20 most common words\n",
        "# 3. Top-20 most common bigrams\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Plot 1: Perplexities comparison\n",
        "models = ['Unigram', 'Bigram', 'Trigram', 'Bigram\\n(Smoothed)']\n",
        "train_perps = [train_perplexity_unigram, train_perplexity_bigram, \n",
        "               train_perplexity_trigram, train_perplexity_smoothed]\n",
        "test_perps = [test_perplexity_unigram, test_perplexity_bigram, \n",
        "              test_perplexity_trigram, test_perplexity_smoothed]\n",
        "\n",
        "x = np.arange(len(models))\n",
        "width = 0.35\n",
        "\n",
        "axes[0, 0].bar(x - width/2, train_perps, width, label='Train', alpha=0.8)\n",
        "axes[0, 0].bar(x + width/2, test_perps, width, label='Test', alpha=0.8)\n",
        "axes[0, 0].set_ylabel('Perplexity')\n",
        "axes[0, 0].set_title('Model Perplexities Comparison')\n",
        "axes[0, 0].set_xticks(x)\n",
        "axes[0, 0].set_xticklabels(models)\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Plot 2: Top-20 most common words\n",
        "top_words = unigram_counts.most_common(20)\n",
        "words, counts = zip(*top_words)\n",
        "axes[0, 1].barh(range(len(words)), counts, color='steelblue')\n",
        "axes[0, 1].set_yticks(range(len(words)))\n",
        "axes[0, 1].set_yticklabels(words)\n",
        "axes[0, 1].set_xlabel('Frequency')\n",
        "axes[0, 1].set_title('Top-20 Most Common Words')\n",
        "axes[0, 1].invert_yaxis()\n",
        "axes[0, 1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Plot 3: Top-20 most common bigrams\n",
        "top_bigrams = bigram_counts.most_common(20)\n",
        "bigrams, counts = zip(*top_bigrams)\n",
        "bigram_labels = [f\"{b[0]}\\n{b[1]}\" for b in bigrams]\n",
        "axes[1, 0].barh(range(len(bigrams)), counts, color='coral')\n",
        "axes[1, 0].set_yticks(range(len(bigrams)))\n",
        "axes[1, 0].set_yticklabels(bigram_labels, fontsize=8)\n",
        "axes[1, 0].set_xlabel('Frequency')\n",
        "axes[1, 0].set_title('Top-20 Most Common Bigrams')\n",
        "axes[1, 0].invert_yaxis()\n",
        "axes[1, 0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Plot 4: Top-20 most common trigrams\n",
        "top_trigrams = trigram_counts.most_common(20)\n",
        "trigrams, counts = zip(*top_trigrams)\n",
        "trigram_labels = [f\"{t[0]} {t[1]} {t[2]}\"[:15] for t in trigrams]\n",
        "axes[1, 1].barh(range(len(trigrams)), counts, color='lightgreen')\n",
        "axes[1, 1].set_yticks(range(len(trigrams)))\n",
        "axes[1, 1].set_yticklabels(trigram_labels, fontsize=8)\n",
        "axes[1, 1].set_xlabel('Frequency')\n",
        "axes[1, 1].set_title('Top-20 Most Common Trigrams')\n",
        "axes[1, 1].invert_yaxis()\n",
        "axes[1, 1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8tjP5OWlgTp"
      },
      "source": [
        "## Part 10: Bonus Challenges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0qvnSfIlgTp"
      },
      "source": [
        "### Challenge 1: Try Different Datasets\n",
        "\n",
        "Load a different dataset from HuggingFace and train your models on it.\n",
        "\n",
        "Suggestions:\n",
        "- `\"wikitext\"` (different versions)\n",
        "- `\"bookcorpus\"`\n",
        "- `\"ptb_text_only\"` (Penn Treebank)\n",
        "- `\"imdb\"` (movie reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK5uI6P1lgTq"
      },
      "outputs": [],
      "source": [
        "# TODO: YOUR CODE HERE\n",
        "# Try loading and training on a different dataset\n",
        "\n",
        "# Example: Using Penn Treebank dataset\n",
        "print(\"Loading Penn Treebank dataset...\")\n",
        "try:\n",
        "    ptb_dataset = load_dataset(\"ptb_text_only\")\n",
        "    print(\"\\nPTB Dataset structure:\")\n",
        "    print(ptb_dataset)\n",
        "    \n",
        "    # Prepare corpus from PTB\n",
        "    print(\"\\nPreparing PTB training corpus...\")\n",
        "    ptb_train_corpus = prepare_corpus(ptb_dataset['train'], max_examples=500)\n",
        "    print(f\"PTB Corpus size: {len(ptb_train_corpus)} sentences\")\n",
        "    \n",
        "    # Build models\n",
        "    print(\"Training models on PTB...\")\n",
        "    ptb_unigram = UnigramModel(ptb_train_corpus)\n",
        "    ptb_bigram = BigramModel(ptb_train_corpus)\n",
        "    ptb_trigram = TrigramModel(ptb_train_corpus)\n",
        "    \n",
        "    # Compare perplexities\n",
        "    ptb_test_corpus = prepare_corpus(ptb_dataset['validation'], max_examples=100)\n",
        "    print(f\"\\nPTB Test corpus size: {len(ptb_test_corpus)}\")\n",
        "    \n",
        "    print(\"\\nPTB Model Perplexities:\")\n",
        "    print(f\"  Unigram: {calculate_perplexity(ptb_unigram, ptb_test_corpus, 'unigram'):.2f}\")\n",
        "    print(f\"  Bigram:  {calculate_perplexity(ptb_bigram, ptb_test_corpus, 'bigram'):.2f}\")\n",
        "    print(f\"  Trigram: {calculate_perplexity(ptb_trigram, ptb_test_corpus, 'trigram'):.2f}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error loading PTB dataset: {e}\")\n",
        "    print(\"You can try other datasets like 'bookcorpus' or 'wikitext'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASmN7zBalgTq"
      },
      "source": [
        "### Challenge 2: Implement Better Smoothing\n",
        "\n",
        "Implement add-k smoothing (where k < 1) or interpolation smoothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUFk6cxflgTq"
      },
      "outputs": [],
      "source": [
        "# TODO: YOUR CODE HERE\n",
        "# Implement add-k smoothing (where k < 1) or interpolation smoothing\n",
        "\n",
        "class BigramModelAddKSmoothing:\n",
        "    \"\"\"Bigram model with add-k smoothing.\"\"\"\n",
        "\n",
        "    def __init__(self, corpus: List[List[str]], k: float = 0.5):\n",
        "        self.unigram_counts = count_unigrams(corpus)\n",
        "        self.bigram_counts = count_bigrams(corpus)\n",
        "        self.vocab = build_vocabulary(corpus)\n",
        "        self.vocab_size = len(self.vocab)\n",
        "        self.k = k  # Smoothing parameter, typically < 1\n",
        "\n",
        "    def probability(self, word: str, previous_word: str) -> float:\n",
        "        \"\"\"Calculate P(word | previous_word) with add-k smoothing.\n",
        "\n",
        "        Formula: P(wi | wi-1) = (C(wi-1, wi) + k) / (C(wi-1) + k*V)\n",
        "        \"\"\"\n",
        "        bigram = (previous_word, word)\n",
        "        count = self.bigram_counts[bigram]\n",
        "        prev_count = self.unigram_counts[previous_word]\n",
        "        \n",
        "        if prev_count > 0:\n",
        "            prob = (count + self.k) / (prev_count + self.k * self.vocab_size)\n",
        "        else:\n",
        "            prob = self.k / (self.k * self.vocab_size)\n",
        "        \n",
        "        return prob\n",
        "\n",
        "    def log_probability(self, word: str, previous_word: str) -> float:\n",
        "        \"\"\"Calculate log P(word | previous_word).\"\"\"\n",
        "        prob = self.probability(word, previous_word)\n",
        "        if prob > 0:\n",
        "            return np.log(prob)\n",
        "        else:\n",
        "            return float('-inf')\n",
        "\n",
        "    def sentence_log_probability(self, sentence: List[str]) -> float:\n",
        "        \"\"\"Calculate log P(sentence).\"\"\"\n",
        "        sum_log_prob = 0.0\n",
        "        for i in range(1, len(sentence)):\n",
        "            prev_word = sentence[i - 1]\n",
        "            word = sentence[i]\n",
        "            sum_log_prob += self.log_probability(word, prev_word)\n",
        "        return sum_log_prob\n",
        "\n",
        "\n",
        "# Compare different k values\n",
        "k_values = [0.1, 0.5, 1.0]\n",
        "print(\"Comparison of Add-K Smoothing with Different K Values\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for k in k_values:\n",
        "    addK_model = BigramModelAddKSmoothing(train_corpus, k=k)\n",
        "    test_perp = calculate_perplexity(addK_model, test_corpus, model_type='bigram')\n",
        "    train_perp = calculate_perplexity(addK_model, train_corpus, model_type='bigram')\n",
        "    \n",
        "    print(f\"K = {k}:\")\n",
        "    print(f\"  Train Perplexity: {train_perp:.2f}\")\n",
        "    print(f\"  Test Perplexity:  {test_perp:.2f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm2w_LlMlgTq"
      },
      "source": [
        "### Challenge 3: Build a Simple Autocomplete System\n",
        "\n",
        "Given a partial sentence, suggest the top-k most likely next words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6PQJPSolgTr"
      },
      "outputs": [],
      "source": [
        "def autocomplete(partial_sentence: str, model: BigramModel, k: int = 5) -> List[Tuple[str, float]]:\n",
        "    \"\"\"\n",
        "    Suggest next words for autocomplete.\n",
        "\n",
        "    Args:\n",
        "        partial_sentence: Incomplete sentence\n",
        "        model: Trained bigram model\n",
        "        k: Number of suggestions\n",
        "\n",
        "    Returns:\n",
        "        List of (word, probability) tuples\n",
        "    \"\"\"\n",
        "    # TODO: Implement this\n",
        "    # Preprocess the partial sentence\n",
        "    tokens = preprocess_text(partial_sentence, add_start_end=False)\n",
        "    \n",
        "    if not tokens:\n",
        "        return []\n",
        "    \n",
        "    # Get the last word\n",
        "    last_word = tokens[-1]\n",
        "    \n",
        "    # Get probabilities for all words after the last word\n",
        "    suggestions = []\n",
        "    for word in model.unigram_counts:\n",
        "        prob = model.probability(word, last_word)\n",
        "        if prob > 0:\n",
        "            suggestions.append((word, prob))\n",
        "    \n",
        "    # Sort by probability and return top k\n",
        "    suggestions.sort(key=lambda x: x[1], reverse=True)\n",
        "    return suggestions[:k]\n",
        "\n",
        "# Test\n",
        "test_partial = \"the cat sat on the\"\n",
        "suggestions = autocomplete(test_partial, bigram_model, k=5)\n",
        "print(f\"Suggestions for: '{test_partial}'\")\n",
        "for i, (word, prob) in enumerate(suggestions, 1):\n",
        "    print(f\"  {i}. {word}: {prob:.4f}\")\n",
        "\n",
        "# Try more examples\n",
        "print(\"\\nMore Autocomplete Examples:\")\n",
        "print(\"=\" * 60)\n",
        "test_partials = [\n",
        "    \"the\",\n",
        "    \"in\",\n",
        "    \"and\",\n",
        "    \"was\"\n",
        "]\n",
        "\n",
        "for partial in test_partials:\n",
        "    suggestions = autocomplete(partial, bigram_model, k=5)\n",
        "    print(f\"\\nAfter '{partial}':\")\n",
        "    for word, prob in suggestions:\n",
        "        print(f\"  {word}: {prob:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
