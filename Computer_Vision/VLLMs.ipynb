{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b6df24c",
   "metadata": {},
   "source": [
    "# Implementation of open VLLMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6988f5d7",
   "metadata": {},
   "source": [
    "## -- Install the required Libraries if needed--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58df3412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qwen_vl_utils\n",
      "  Downloading qwen_vl_utils-0.0.14-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting av (from qwen_vl_utils)\n",
      "  Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils) (25.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils) (11.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->qwen_vl_utils) (2025.11.12)\n",
      "Downloading qwen_vl_utils-0.0.14-py3-none-any.whl (8.1 kB)\n",
      "Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (40.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: av, qwen_vl_utils\n",
      "Successfully installed av-16.0.1 qwen_vl_utils-0.0.14\n"
     ]
    }
   ],
   "source": [
    "pip install qwen_vl_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae88311b",
   "metadata": {},
   "source": [
    "## 1-Import Required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ae38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import Qwen2VLForConditionalGeneration, Qwen2VLProcessor\n",
    "from qwen_vl_utils import process_vision_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe216c",
   "metadata": {},
   "source": [
    "## 2- Load the Pre-trained Model and proces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa8c8dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4deb8cc9c7341aa88a6e7a32b10e5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df4d85a9782497999d8b5ee8cf436b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee763777a5b479fb3593d9d33c3ab1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f29776f88b74896a3840df8993f1f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/3.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42b7791869447559198aae28eb93ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5ca7622af541d98fae07c20b3cec45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c283ed6d253b4fd4b94468bf5c2eee91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271cc53a65b84d2c820e543eb745d2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e665b0bfac46eb8739b22464b876e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46649cc545d4d1c8908a2bdfb5ab958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/244 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472eb642a2b545dca5b40ed6234b420f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd09f2d12954848a479d115732a6136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81627d49128e493eb8571a9dbf3e3184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3710861248c14f44a21bd32db82cb2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324636b90b114207840f1f05c2bb5a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7cfba227c74d91a62d1609d740f131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "processor = Qwen2VLProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfffba64",
   "metadata": {},
   "source": [
    "## 3-Generate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf044786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(image_path, query, max_new_tokens=256):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    sample = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": \"You are a Vision Language Model. Answer concisely.\"}]},\n",
    "            {\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": image}, {\"type\": \"text\", \"text\": query}]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    text_input = processor.apply_chat_template(sample['messages'][1:2], tokenize=False, add_generation_prompt=True)\n",
    "    image_inputs, _ = process_vision_info(sample['messages'])\n",
    "\n",
    "    model_inputs = processor(text=[text_input], images=image_inputs, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=max_new_tokens)\n",
    "\n",
    "    trimmed_generated_ids = [out_ids[len(in_ids):] for in_ids, out_ids in zip(model_inputs.input_ids, generated_ids)]\n",
    "\n",
    "    output_text = processor.batch_decode(trimmed_generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "\n",
    "    return output_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677fa959",
   "metadata": {},
   "source": [
    "## 4-Running the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab831239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /content\n",
      "Absolute image path: /content/Flag_of_Cameroon.svg.png\n",
      "Image exists: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# current working directory\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "image_path = \"Flag_of_Cameroon.svg.png\"\n",
    "# absolute path for the image (uses existing `image_path` variable)\n",
    "abs_image_path = os.path.abspath(image_path)\n",
    "print(\"Absolute image path:\", abs_image_path)\n",
    "\n",
    "# check if the image exists\n",
    "print(\"Image exists:\", os.path.exists(abs_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ae27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Describe this Image\"\n",
    "answer = generate_answer(image_path, query)\n",
    "print(\"Generated Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb0309",
   "metadata": {},
   "source": [
    "# THANK YOU "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
